# Conversations

This feature provides a detailed view of AI agent-customer interactions, helping businesses to assess the agent’s performance, identify resolution patterns, and optimize its behavior. By analyzing individual conversations, you can refine their AI agent’s responses, improve automation efficiency, and enhance customer satisfaction.

<figure><img src="../../../.gitbook/assets/image (20).png" alt=""><figcaption></figcaption></figure>

## How to analyze conversations

Use the following tools and insights to evaluate conversation quality and AI agent performance:

* Filter: Sort conversations by resolution status, CSAT rating, handoff occurrence, and conversation category to focus on specific insights.
* Pattern detection: Identify patterns in AI agent effectiveness, such as recurring issues, that merits human intervention or AI agent optimization.
* In-depth analysis: Click on any row in the conversation table to view detailed information and assess how the AI agent handled the exchange in a scorecard. Use this view to evaluate specific responses and pinpoint areas for improvement.

<figure><img src="../../../.gitbook/assets/image (70) (1).png" alt=""><figcaption></figcaption></figure>

### Review the conversation

Each conversation has an AI agent scorecard on its side panel. Rate the AI agent's performance and, if it was poor, leave a brief rationale why. You can also make notes of the things you've noticed in the particular conversation.

Here you can assess the AI agent's responses based on the following criteria:

* **Tone**: the overall manner and attitude conveyed by the AI agent in its communication.
* **Clarity and readability**: how easy the AI agent's responses were to understand.
* **Relevance**: how well the AI agent's answers and information directly addressed the user's questions and needs.
* **Solution effectiveness**: how successful the AI agent was in resolving the user's issue or fulfilling their request.
